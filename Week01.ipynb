{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPO2R+J6tpU9qwenusWQLEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d896c51bbd11404c9d75ddf4dd3c27b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c07d1f5983f347358d7f639b772a3a4a",
              "IPY_MODEL_365977d89c23435d8de1ac19afd9f6a8",
              "IPY_MODEL_3d1f6c92a2274107b52e00ea37dda441"
            ],
            "layout": "IPY_MODEL_208129611ad146cc97dbf6b81b99431b"
          }
        },
        "c07d1f5983f347358d7f639b772a3a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc6dc780bf8f437d9c23e3155aa6eafd",
            "placeholder": "​",
            "style": "IPY_MODEL_743d03b8728846ec9c2cd4d0119803c4",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "365977d89c23435d8de1ac19afd9f6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d01a376b53b34cc0aeac742e8d99ee7b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1a05e0ca15a4baebe016ae02f47d62c",
            "value": 2
          }
        },
        "3d1f6c92a2274107b52e00ea37dda441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b6ad6909574f3e99447c9fad58cf92",
            "placeholder": "​",
            "style": "IPY_MODEL_564ee92a57c141698d170616748eee25",
            "value": " 2/2 [00:00&lt;00:00, 20.40it/s]"
          }
        },
        "208129611ad146cc97dbf6b81b99431b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc6dc780bf8f437d9c23e3155aa6eafd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "743d03b8728846ec9c2cd4d0119803c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d01a376b53b34cc0aeac742e8d99ee7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a05e0ca15a4baebe016ae02f47d62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12b6ad6909574f3e99447c9fad58cf92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "564ee92a57c141698d170616748eee25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niikun/lecture-ai-engineering/blob/master/Week01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Streamlit"
      ],
      "metadata": {
        "id": "EHc9LwI_Ux9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "SvG4WC0SOHIz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ANWUUQO9mJ5",
        "outputId": "eee139f5-01b7-4bf0-d621-379877dd2539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bk517aYl_oxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk.download('punkt') とは？\n",
        "これは、**英語の文章を単語や文に分けるための道具（辞書）**をダウンロードする命令です。\n",
        "\n",
        "punkt（プンクト） というのは、\n",
        "\n",
        "「文を分けるルール（たとえば . や ! の後に文が終わる）」をまとめたものです。\n",
        "\n",
        "nltk（自然言語ツールキット）というライブラリの中にある、文の区切りを見つけるためのデータセットです。"
      ],
      "metadata": {
        "id": "Y5CXfaxa_I2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\",quiet=False)\n",
        "nltk.download('punkt_tab')\n",
        "text = \"Hello, how are you? I'm learning NLP with NLTK. It's fun!\"\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFkoi5Mm_IQp",
        "outputId": "c4aa7a06-f15b-42d3-d434-ddf27f12264d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello, how are you?', \"I'm learning NLP with NLTK.\", \"It's fun!\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLEUスコアを計算する関数 sentence_bleu を nltk_sentence_bleu という名前で使えるようにしています。\n",
        "from nltk.translate.bleu_score import sentence_bleu as nltk_sentence_bleu\n",
        "# 文を単語に分ける関数 word_tokenize を nltk_word_tokenize という名前で使えるようにしています。\n",
        "from nltk.tokenize import word_tokenize as nltk_word_tokenize\n",
        "print(\"NLTK loaded successfully.\") # デバッグ用"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAonfcBMAGLr",
        "outputId": "fcf4c678-aa6d-4e07-fee6-b31a3651581f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word_tokenizeの事例"
      ],
      "metadata": {
        "id": "MEgJXQ_yCxDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_word_tokenize(\"Hello, how are you?\")\n",
        "# → ['Hello', ',', 'how', 'are', 'you', '?']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uinRNmqtAWqC",
        "outputId": "2c71b175-540f-4fa0-926b-cd9dd721db6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', ',', 'how', 'are', 'you', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bleuの事例"
      ],
      "metadata": {
        "id": "88gQmsu5C9up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# punktデータをダウンロード（単語分割のため）\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 正解の文（例：先生の答え）\n",
        "reference = \"The cat is on the mat.\"\n",
        "\n",
        "# 生徒の答え（例：AIが出した回答）\n",
        "candidate = \"The cat sat on the mat.\"\n",
        "\n",
        "# 単語に分ける\n",
        "reference_tokens = nltk_word_tokenize(reference.lower())  # 小文字にしてトークナイズ\n",
        "candidate_tokens = nltk_word_tokenize(candidate.lower())\n",
        "reference_tokens,candidate_tokens"
      ],
      "metadata": {
        "id": "hubTFHxuFmjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "062f2de0-1de4-4c77-e27f-f7b66ad0f496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['the', 'cat', 'is', 'on', 'the', 'mat', '.'],\n",
              " ['the', 'cat', 'sat', 'on', 'the', 'mat', '.'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLEUスコアの計算（4-gramまで使う）\n",
        "bleu_score = nltk_sentence_bleu([reference_tokens], candidate_tokens, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "print(\"🔵 BLEUスコア:\", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f7WsZDYAv95",
        "outputId": "31ad4d80-91be-405a-8f8b-87ed5361c2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔵 BLEUスコア: 0.488923022434901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BLEUスコアの目安（ざっくり）\n",
        "\n",
        "スコア   | 評価の目安  \n",
        "1.0      | 完全に一致  \n",
        "0.6〜0.8 | ほぼ正解  \n",
        "0.3〜0.5 | 部分的に一致  \n",
        "0.0〜0.2 | ほぼ不一致  "
      ],
      "metadata": {
        "id": "lSZ-fRRnD5Ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 簡易関数"
      ],
      "metadata": {
        "id": "XKksqdgKFXK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nltk_sentence_bleu2(references, candidate):\n",
        "    # 簡易BLEUスコア（完全一致/部分一致）\n",
        "    ref_words = set(references[0])\n",
        "    cand_words = set(candidate)\n",
        "    common_words = ref_words.intersection(cand_words)\n",
        "    precision = len(common_words) / len(cand_words) if cand_words else 0\n",
        "    recall = len(common_words) / len(ref_words) if ref_words else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f1"
      ],
      "metadata": {
        "id": "XUXZfQi6EeWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference = \"The cat is on the mat.\"\n",
        "candidate = \"The cat sat on the mat.\"\n",
        "ref_words = set(reference)\n",
        "cand_words = set(candidate)\n",
        "ref_words,len(ref_words),cand_words,len(cand_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ashU7v93GlM3",
        "outputId": "33d712a0-aecb-4a6e-dede-f05fdf99fe5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({' ', '.', 'T', 'a', 'c', 'e', 'h', 'i', 'm', 'n', 'o', 's', 't'},\n",
              " 13,\n",
              " {' ', '.', 'T', 'a', 'c', 'e', 'h', 'm', 'n', 'o', 's', 't'},\n",
              " 12)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_words = ref_words.intersection(cand_words)\n",
        "common_words,len(common_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndv1gnBgG4xN",
        "outputId": "c5c6d447-c6de-471b-b370-256696552bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({' ', '.', 'T', 'a', 'c', 'e', 'h', 'm', 'n', 'o', 's', 't'}, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ref_words.difference(cand_words)"
      ],
      "metadata": {
        "id": "qX-OZFSSG7EI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c00235c-9aed-45b3-8ab7-696ed569f56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'i'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "precision（精度） = 回答に含まれる単語のうち、正解にある割合  \n",
        "→「どれだけ余計なこと言ってないか」  \n",
        "\n",
        "recall（再現率） = 正解に含まれる単語のうち、回答に入ってた割合  \n",
        "→「必要なことをどれだけ言えているか」  "
      ],
      "metadata": {
        "id": "aK-rZu3IHeel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision = len(common_words) / len(cand_words)\n",
        "recall = len(common_words) / len(ref_words)\n",
        "precision,recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtTTlBCbHG_i",
        "outputId": "233fe530-9f5c-4317-cb92-fb626875e5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 0.9230769230769231)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "f1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z6hCS-oHZx4",
        "outputId": "e50ea62a-970a-4ac8-95b0-062a62dd5c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9600000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 単語数のカウント"
      ],
      "metadata": {
        "id": "FnkmiyxnJSJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install janome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcxykvpeJldK",
        "outputId": "fef75ebd-7dbb-4189-9d69-51b5a982e526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting janome\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer"
      ],
      "metadata": {
        "id": "rzYfIuywHtOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "bhuQckfTcFQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference = \"吾輩は猫である\"\n",
        "for token in tokenizer.tokenize(reference):\n",
        "    print(token)"
      ],
      "metadata": {
        "id": "IVBiFPBiciq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683398e8-d318-4782-a555-02168332b81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "吾輩\t名詞,代名詞,一般,*,*,*,吾輩,ワガハイ,ワガハイ\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
            "猫\t名詞,一般,*,*,*,*,猫,ネコ,ネコ\n",
            "で\t助動詞,*,*,*,特殊・ダ,連用形,だ,デ,デ\n",
            "ある\t助動詞,*,*,*,五段・ラ行アル,基本形,ある,アル,アル\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = list(tokenizer.tokenize(reference))\n",
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxngNzNCcn8Y",
        "outputId": "a3af0389-5c73-4801-a650-38a74ab0a660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 類似度の計算"
      ],
      "metadata": {
        "id": "pLbL09aCOk18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF という方法を使って、\n",
        "\n",
        "単語の重要さ（よく出るけど全体ではめずらしい単語）を数字にしてくれる「変換器（ベクトライザー）」を作っています。"
      ],
      "metadata": {
        "id": "CphyUFEqPZxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "_W7aqsPhcr9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_lower = \"The cat is on the mat.\"\n",
        "correct_answer_lower = \"The cat sat on the mat.\"\n",
        "\n",
        "tfidf_matrix = vectorizer.fit_transform([answer_lower, correct_answer_lower])\n",
        "print(tfidf_matrix,tfidf_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj4FiE_jPAGv",
        "outputId": "f336fcec-7df8-4864-df88-a746b901e090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 10 stored elements and shape (2, 6)>\n",
            "  Coords\tValues\n",
            "  (0, 5)\t0.6675821723880022\n",
            "  (0, 0)\t0.3337910861940011\n",
            "  (0, 1)\t0.4691317250431934\n",
            "  (0, 3)\t0.3337910861940011\n",
            "  (0, 2)\t0.3337910861940011\n",
            "  (1, 5)\t0.6675821723880022\n",
            "  (1, 0)\t0.3337910861940011\n",
            "  (1, 3)\t0.3337910861940011\n",
            "  (1, 2)\t0.3337910861940011\n",
            "  (1, 4)\t0.4691317250431934 (2, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix[0:1],tfidf_matrix[1:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U4lmp4ePMvM",
        "outputId": "910793e1-0374-4084-f25c-0ff07e01e8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              " \twith 5 stored elements and shape (1, 6)>,\n",
              " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              " \twith 5 stored elements and shape (1, 6)>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
        "similarity_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV77va5oQefh",
        "outputId": "cb70f1af-b942-4fa9-e67f-907b8fa46553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.77991542]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Database"
      ],
      "metadata": {
        "id": "nSPkiFUbOAOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3"
      ],
      "metadata": {
        "id": "dbifSemPQnvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sqlite3.connect(\"test.db\") as conn:\n",
        "    c = conn.cursor()\n",
        "    c.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS test_table(\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            name TEXT,\n",
        "            age INTEGER)\n",
        "        \"\"\"\n",
        "        )\n",
        "\n",
        "    c.execute(\"INSERT INTO test_table (name,age) VALUES ('niikun',58)\")\n",
        "    c.execute(\"INSERT INTO test_table (name,age) VALUES ('sankun',59)\")\n",
        "    c.execute(\"INSERT INTO test_table (name,age) VALUES ('yonkun',60)\")\n",
        "    conn.commit()\n",
        "\n",
        "    c.execute(\"SELECT * FROM test_table\")\n",
        "\n",
        "    for row in c.fetchall():\n",
        "        print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJbnPl3gOfo0",
        "outputId": "c04e76ea-2480-4eb1-d903-3afada718193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 'niikun', 58)\n",
            "(2, 'sankun', 59)\n",
            "(3, 'yonkun', 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM"
      ],
      "metadata": {
        "id": "SduIPlO7RgLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iyOXc1jQQtX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njY3iYlxShbG",
        "outputId": "c08dc219-a210-4f58-daae-c2090ddbd770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.35.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m140.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m136.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.44.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "import streamlit as st\n",
        "import time\n",
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "TAMSCZU6PY1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"google/gemma-2-2b-jpn-it\""
      ],
      "metadata": {
        "id": "TxOeAm6_SdHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=MODEL_NAME,\n",
        "            model_kwargs={\"torch_dtype\":torch.bfloat16},\n",
        "            device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "d896c51bbd11404c9d75ddf4dd3c27b1",
            "c07d1f5983f347358d7f639b772a3a4a",
            "365977d89c23435d8de1ac19afd9f6a8",
            "3d1f6c92a2274107b52e00ea37dda441",
            "208129611ad146cc97dbf6b81b99431b",
            "fc6dc780bf8f437d9c23e3155aa6eafd",
            "743d03b8728846ec9c2cd4d0119803c4",
            "d01a376b53b34cc0aeac742e8d99ee7b",
            "d1a05e0ca15a4baebe016ae02f47d62c",
            "12b6ad6909574f3e99447c9fad58cf92",
            "564ee92a57c141698d170616748eee25"
          ]
        },
        "id": "1Esu0X8bSbQO",
        "outputId": "f9346955-1f91-4a82-d311-ee118557d9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d896c51bbd11404c9d75ddf4dd3c27b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\":\"user\",\"content\":\"LLMとはなにですか？\"}\n",
        "]\n",
        "outputs = pipe(messages,max_new_tokens=512,do_sample=True,temperature=0.7,top_p=0.9)\n",
        "\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJFfgxkKdq3-",
        "outputId": "41300f04-a5b0-493f-dd53-dd6a0f17b75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': [{'role': 'user', 'content': 'LLMとはなにですか？'}, {'role': 'assistant', 'content': 'LLM（Large Language Model）とは、**大量のテキストデータから学習した、人間のような文章を生成・理解する AI モデル**です。\\n\\n簡単に言うと、**大量のテキスト資料を学習することで、自然な文章を生成したり、質問に答えたり、翻訳したり、文章の要約したり、様々なタスクを実行できる**ことを意味します。\\n\\n**具体的には:**\\n\\n* **文章生成:** 小説、詩、記事など、様々な種類の文章を生成できます。\\n* **翻訳:** 多言語での翻訳が可能。\\n* **質問応答:**  質問に対して、適切な答えを返すことができます。\\n* **要約:** 長い文章を要約して、重要なポイントを抽出できます。\\n* **コード生成:**  プログラミング言語のコードを生成できます。\\n\\n\\n**有名なLLM例:**\\n\\n* **GPT-3 (Generative Pre-trained Transformer 3):** OpenAIによって開発された、非常に高度なLLMです。\\n* **LaMDA (Language Model for Dialogue Applications):** Googleによって開発された、対話型のLLMです。\\n* **BERT (Bidirectional Encoder Representations from Transformers):** Googleによって開発された、文章理解に特化したLLMです。\\n\\n\\n\\nLLMは、様々な分野で応用が期待されています。\\n \\n\\n\\n'}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if outputs and isinstance(outputs,list) and outputs[0].get(\"generated_text\"):\n",
        "    print(outputs[0][\"generated_text\"][-1].get(\"content\",\"\").strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVnzZmiteouM",
        "outputId": "459515c2-81f9-4ad9-9a84-38806995e22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM（Large Language Model）とは、**大量のテキストデータから学習した、人間のような文章を生成・理解する AI モデル**です。\n",
            "\n",
            "簡単に言うと、**大量のテキスト資料を学習することで、自然な文章を生成したり、質問に答えたり、翻訳したり、文章の要約したり、様々なタスクを実行できる**ことを意味します。\n",
            "\n",
            "**具体的には:**\n",
            "\n",
            "* **文章生成:** 小説、詩、記事など、様々な種類の文章を生成できます。\n",
            "* **翻訳:** 多言語での翻訳が可能。\n",
            "* **質問応答:**  質問に対して、適切な答えを返すことができます。\n",
            "* **要約:** 長い文章を要約して、重要なポイントを抽出できます。\n",
            "* **コード生成:**  プログラミング言語のコードを生成できます。\n",
            "\n",
            "\n",
            "**有名なLLM例:**\n",
            "\n",
            "* **GPT-3 (Generative Pre-trained Transformer 3):** OpenAIによって開発された、非常に高度なLLMです。\n",
            "* **LaMDA (Language Model for Dialogue Applications):** Googleによって開発された、対話型のLLMです。\n",
            "* **BERT (Bidirectional Encoder Representations from Transformers):** Googleによって開発された、文章理解に特化したLLMです。\n",
            "\n",
            "\n",
            "\n",
            "LLMは、様々な分野で応用が期待されています。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(pipe, user_question):\n",
        "    \"\"\"LLMを使用して質問に対する回答を生成する\"\"\"\n",
        "    if pipe is None:\n",
        "        return \"モデルがロードされていないため、回答を生成できません。\", 0\n",
        "\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": user_question},\n",
        "        ]\n",
        "        # max_new_tokensを調整可能にする（例）\n",
        "        outputs = pipe(messages, max_new_tokens=512, do_sample=True, temperature=0.7, top_p=0.9)\n",
        "\n",
        "        # Gemmaの出力形式に合わせて調整が必要な場合がある\n",
        "        # 最後のassistantのメッセージを取得\n",
        "        assistant_response = \"\"\n",
        "        if outputs and isinstance(outputs, list) and outputs[0].get(\"generated_text\"):\n",
        "            if isinstance(outputs[0][\"generated_text\"], list) and len(outputs[0][\"generated_text\"]) > 0:\n",
        "                # messages形式の場合\n",
        "                last_message = outputs[0][\"generated_text\"][-1]\n",
        "                if last_message.get(\"role\") == \"assistant\":\n",
        "                    assistant_response = last_message.get(\"content\", \"\").strip()\n",
        "            elif isinstance(outputs[0][\"generated_text\"], str):\n",
        "                # 単純な文字列の場合（古いtransformers？） - プロンプト部分を除く処理が必要かも\n",
        "                # この部分はモデルやtransformersのバージョンによって調整が必要\n",
        "                full_text = outputs[0][\"generated_text\"]\n",
        "                # 簡単な方法：ユーザーの質問以降の部分を取得\n",
        "                prompt_end = user_question\n",
        "                response_start_index = full_text.find(prompt_end) + len(prompt_end)\n",
        "\n",
        "                possible_response = full_text[response_start_index:].strip()\n",
        "                if \"<start_of_turn>model\" in possible_response:\n",
        "                    assistant_response = possible_response.split(\"<start_of_turn>model\\n\")[-1].strip()\n",
        "                else:\n",
        "                    assistant_response = possible_response\n",
        "\n",
        "        if not assistant_response:\n",
        "            print(\"Warning: Could not extract assistant response.\")\n",
        "            assistant_response = \"回答が見つかりませんでした。\"\n",
        "\n",
        "        end_time = time.time()\n",
        "        response_time = end_time - start_time\n",
        "        print(f\"Generated response in {response_time:.2f} s\")\n",
        "        return assistant_response, response_time\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"回答生成中にエラーが発生しました: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return \"エラーが発生しました。\", 0"
      ],
      "metadata": {
        "id": "QUbqlq6V-V61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(pipe,\"LLMとはなにですか？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyCzxRnH_yzU",
        "outputId": "28e0b5a9-415d-4084-a045-1b9fa2b9f89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated response in 18.76 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('LLMは**Large Language Model**の略で、**大規模言語モデル**を指します。\\n\\n簡単に言うと、**膨大な量のテキストデータから学習した、人間のような文章を生成・理解できるAIモデル**です。\\n\\n\\n**具体的に言うと、以下のような能力を持っています:**\\n\\n* **文章の生成:** 小説、詩、記事、メール、手紙など、様々な種類の文章を生成できます。\\n* **文章の翻訳:**  複数の言語間で文章を翻訳できます。\\n* **文章の要約:**  長い文章を短くまとめたり、重要なポイントを抽出したりできます。\\n* **質問応答:**  ユーザーからの質問に対して、適切な答えを返します。\\n* **会話:**  人間と自然な会話をすることができます。\\n\\n\\n\\n**LLMの例:**\\n\\n* **GPT-3 (Generative Pre-trained Transformer 3)**: OpenAIが開発した、最も有名なLLMの一つ。\\n* **LaMDA (Language Model for Dialogue Applications)**: Googleが開発した、会話に特化したLLM。\\n* **BERT (Bidirectional Encoder Representations from Transformers)**: Googleが開発した、文章理解に特化したLLM。\\n\\n\\n\\n**LLMは、様々な分野で活用されています:**\\n\\n* **自動翻訳:**  より自然で正確な翻訳が可能になる。\\n* **コンテンツ生成:**  ブログ記事、広告、ウェブサイトコンテンツの自動生成が可能になる。\\n* **カスタマーサポート:**  より効率的な顧客対応が可能になる。\\n* **教育:**  学習のサポートや教材の生成が可能になる。',\n",
              " 18.756808280944824)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UI"
      ],
      "metadata": {
        "id": "ncNM5FvCxkIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CBLvwjV2HBm",
        "outputId": "94a5703b-6254-4f0b-c24f-2ce671abf5cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.4-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "ngrok_token = userdata.get('ngrok')"
      ],
      "metadata": {
        "id": "Sz_bOSmc2u0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken $ngrok_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilGtkxQF2oVe",
        "outputId": "c974a181-2a87-41e6-8a8c-c83b4339e5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run streamlit_ui.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAFrSM9LzUPv",
        "outputId": "2161a31e-e167-40fd-e58f-ae44a6ea6d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "公開URL: https://2330-35-198-240-31.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.198.240.31:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[31m──\u001b[0m\u001b[31m────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────\u001b[0m\u001b[31m──\u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mexec_code.py\u001b[0m: \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[94m121\u001b[0m in \u001b[92mexec_func_with_error_handling\u001b[0m                                                 \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001b[0m\u001b[1;33mscript_runner\u001b[0m \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m640\u001b[0m in \u001b[92mcode_to_exec\u001b[0m                                                              \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[2;33m/content/\u001b[0m\u001b[1;33mstreamlit_ui.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m                                                                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 1 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mstreamlit\u001b[0m \u001b[94mas\u001b[0m \u001b[4;96mst\u001b[0m                                                          \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m \u001b[31m❱ \u001b[0m 2 \u001b[1;4;94mfrom\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;96mllm\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4;94mimport\u001b[0m\u001b[1;4m generate_response, pipe\u001b[0m                                         \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 3 \u001b[0m                                                                                \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mmain\u001b[0m():                                                                     \u001b[31m \u001b[0m\n",
            "\u001b[31m \u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0mst.subheader(\u001b[33m\"\u001b[0m\u001b[33m質問を入力してください\u001b[0m\u001b[33m\"\u001b[0m)                                      \u001b[31m \u001b[0m\n",
            "\u001b[31m────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
            "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'llm'\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "dX0kEmKr65uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_ui.py\n",
        "import streamlit as st\n",
        "from llm import generate_response, pipe\n",
        "\n",
        "def main():\n",
        "    st.subheader(\"質問を入力してください\")\n",
        "    user_question = st.text_area(\"質問\", key=\"question_input\", height=100, value=st.session_state.get(\"current_question\", \"\"))\n",
        "    submit_button = st.button(\"送信\")\n",
        "\n",
        "    if submit_button and user_question:\n",
        "        st.session_state.current_question = user_question\n",
        "        st.session_state.current_answer = \"\" # 回答をリセット\n",
        "        st.session_state.feedback_geven = False # フィードバック状態もリセット\n",
        "\n",
        "        with st.spinner(\"モデルが回答を生成中\"):\n",
        "            answer,response_time = generate_response(pipe, user_question)\n",
        "            st.session_state.current_answer = answer\n",
        "            st.session_state.response_time = response_time\n",
        "            st.reurn()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmRlDW-KfZ1s",
        "outputId": "7dfe4764-b1a1-453c-c562-c6d71b244f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_ui.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.FastAPI\n"
      ],
      "metadata": {
        "id": "q0KfnuqTUhYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FastAPI"
      ],
      "metadata": {
        "id": "qnrb7XUYUoZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn[\"standard\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj1c-_dTVSKI",
        "outputId": "51ce6b93-2653-4ee3-c352-33964ade70ef"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn[standard]\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]) (0.14.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard])\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard])\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]) (6.0.2)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard])\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]) (15.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, uvicorn, python-dotenv, httptools, watchfiles, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.12 httptools-0.6.4 python-dotenv-1.1.0 starlette-0.46.2 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile fastapi_test.py\n",
        "\n",
        "from fastapi import FastAPI\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Hello World\"}\n",
        "\n"
      ],
      "metadata": {
        "id": "13aWr0pOzB8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b2facf-b012-4322-eb67-648d8e5ca07b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fastapi_test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TItYaj2WjZ7",
        "outputId": "1a433a7f-04dd-4214-bf65-5c6799ebb1c4"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "ngrok_token = userdata.get('ngrok')"
      ],
      "metadata": {
        "id": "29SNNt3GWdcR"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken $ngrok_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDo5SjaXWq_n",
        "outputId": "6e6aca65-164f-4f12-896b-5a5cf432e922"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!uvicorn fastapi_test:app --reload"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqMz4bW_WOap",
        "outputId": "b202a445-dd5e-4233-862c-04140703c911"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "公開URL: https://03c0-35-198-240-31.ngrok-free.app\n",
            "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content']\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m64968\u001b[0m] using \u001b[36m\u001b[1mWatchFiles\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m64970\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     2400:2410:b240:3300:4498:da7b:2f2:3155:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2400:2410:b240:3300:4498:da7b:2f2:3155:0 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m64970\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m64968\u001b[0m]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "Ob0jiHgWXAqs"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jay7UQWAXyyc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}