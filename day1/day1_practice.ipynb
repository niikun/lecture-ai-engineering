{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpnWBP5ELSI"
      },
      "source": [
        "# 実践演習 Day 1：streamlitとFastAPIのデモ\n",
        "このノートブックでは以下の内容を学習します。\n",
        "\n",
        "- 必要なライブラリのインストールと環境設定\n",
        "- Hugging Faceからモデルを用いたStreamlitのデモアプリ\n",
        "- FastAPIとngrokを使用したAPIの公開方法\n",
        "\n",
        "演習を始める前に、HuggingFaceとngrokのアカウントを作成し、\n",
        "それぞれのAPIトークンを取得する必要があります。\n",
        "\n",
        "\n",
        "演習の時間では、以下の3つのディレクトリを順に説明します。\n",
        "\n",
        "1. 01_streamlit_UI\n",
        "2. 02_streamlit_app\n",
        "3. 03_FastAPI\n",
        "\n",
        "2つ目や3つ目からでも始められる様にノートブックを作成しています。\n",
        "\n",
        "復習の際にもこのノートブックを役立てていただければと思います。\n",
        "\n",
        "### 注意事項\n",
        "「02_streamlit_app」と「03_FastAPI」では、GPUを使用します。\n",
        "\n",
        "これらを実行する際は、Google Colab画面上のメニューから「編集」→ 「ノートブックの設定」\n",
        "\n",
        "「ハードウェアアクセラレーター」の項目の中から、「T4 GPU」を選択してください。\n",
        "\n",
        "このノートブックのデフォルトは「CPU」になっています。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtHkJOgELSL"
      },
      "source": [
        "# 環境変数の設定（1~3共有）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FjBp4MMQHM"
      },
      "source": [
        "GitHubから演習用のコードをCloneします。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jcWglNkhHzx_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AIXMavdDEP8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "844fad4c-3338-4d93-9e50-ffed66050c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lecture-ai-engineering'...\n",
            "remote: Enumerating objects: 216, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 216 (delta 59), reused 62 (delta 40), pack-reused 112 (from 3)\u001b[K\n",
            "Receiving objects: 100% (216/216), 122.97 KiB | 11.18 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/niikun/lecture-ai-engineering.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8n7yZ_vs1K"
      },
      "source": [
        "必要なAPIトークンを.envに設定します。\n",
        "\n",
        "「lecture-ai-engineering/day1」の配下に、「.env_template」ファイルが存在しています。\n",
        "\n",
        "隠しファイルのため表示されていない場合は、画面左側のある、目のアイコンの「隠しファイルの表示」ボタンを押してください。\n",
        "\n",
        "「.env_template」のファイル名を「.env」に変更します。「.env」ファイルを開くと、以下のような中身になっています。\n",
        "\n",
        "\n",
        "```\n",
        "HUGGINGFACE_TOKEN=\"hf-********\"\n",
        "NGROK_TOKEN=\"********\"\n",
        "```\n",
        "ダブルクオーテーションで囲まれた文字列をHuggingfaceのアクセストークンと、ngrokの認証トークンで書き変えてください。\n",
        "\n",
        "それぞれのアカウントが作成済みであれば、以下のURLからそれぞれのトークンを取得できます。\n",
        "\n",
        "- Huggingfaceのアクセストークン\n",
        "https://huggingface.co/docs/hub/security-tokens\n",
        "\n",
        "- ngrokの認証トークン\n",
        "https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "書き換えたら、「.env」ファイルをローカルのPCにダウンロードしてください。\n",
        "\n",
        "「01_streamlit_UI」から「02_streamlit_app」へ進む際に、CPUからGPUの利用に切り替えるため、セッションが一度切れてしまいます。\n",
        "\n",
        "その際に、トークンを設定した「.env」ファイルは再作成することになるので、その手間を減らすために「.env」ファイルをダウンロードしておくと良いです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py1BFS5RqcSS"
      },
      "source": [
        "「.env」ファイルを読み込み、環境変数として設定します。次のセルを実行し、最終的に「True」が表示されていればうまく読み込めています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bvEowFfg5lrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ee1095-4b9b-4d9a-d7bd-fee488de9f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n",
            "/content/lecture-ai-engineering/day1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "%cd /content/lecture-ai-engineering/day1\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os0Yk6gaELSM"
      },
      "source": [
        "# 01_streamlit_UI\n",
        "\n",
        "ディレクトリ「01_streamlit_UI」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S28XgOm0ELSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9cb37b-e25b-4217-a60b-5656eaafa387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/01_streamlit_UI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/01_streamlit_UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVp-aEIkELSM"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nBe41LFiELSN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyw6VHaTELSN"
      },
      "source": [
        "ngrokのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYw1q0iXELSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c962957c-31c9-44e9-e8c8-054cce88e233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RssTcD_IELSN"
      },
      "source": [
        "アプリを起動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-E7ucR6ELSN"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbYyXVFjELSN"
      },
      "source": [
        "公開URLの後に記載されているURLにブラウザでアクセスすると、streamlitのUIが表示されます。\n",
        "\n",
        "app.pyのコメントアウトされている箇所を編集することで、UIがどの様に変化するか確認してみましょう。\n",
        "\n",
        "streamlitの公式ページには、ギャラリーページがあります。\n",
        "\n",
        "streamlitを使うとpythonという一つの言語であっても、様々なUIを実現できることがわかると思います。\n",
        "\n",
        "https://streamlit.io/gallery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtP5GLOELSN"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ek9QgahELSO"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-T8tFpyELSO"
      },
      "source": [
        "# 02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqogFQKnELSO"
      },
      "source": [
        "\n",
        "ディレクトリ「02_streamlit_app」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeEjlJ7uELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81543c3d-d203-4460-e8de-26024d7e5e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/02_streamlit_app\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XUH2AstELSO"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDqvI4V3ELSO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO31umGZELSO"
      },
      "source": [
        "ngrokとhuggigfaceのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPxTiEWQELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0c1f1e-3c18-4cbb-f74b-d1a9ce2fc7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "The token `agent` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `agent`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4WrELLELSP"
      },
      "source": [
        "stramlitでHuggingfaceのトークン情報を扱うために、streamlit用の設定ファイル（.streamlit）を作成し、トークンの情報を格納します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W184-a7qFP0W"
      },
      "outputs": [],
      "source": [
        "# .streamlit/secrets.toml ファイルを作成\n",
        "import os\n",
        "import toml\n",
        "\n",
        "# 設定ファイルのディレクトリ確保\n",
        "os.makedirs('.streamlit', exist_ok=True)\n",
        "\n",
        "# 環境変数から取得したトークンを設定ファイルに書き込む\n",
        "secrets = {\n",
        "    \"huggingface\": {\n",
        "        \"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# 設定ファイルを書き込む\n",
        "with open('.streamlit/secrets.toml', 'w') as f:\n",
        "    toml.dump(secrets, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK0vI_xKELSP"
      },
      "source": [
        "アプリを起動します。\n",
        "\n",
        "02_streamlit_appでは、Huggingfaceからモデルをダウンロードするため、初回起動には2分程度時間がかかります。\n",
        "\n",
        "この待ち時間を利用して、app.pyのコードを確認してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gemma 2"
      ],
      "metadata": {
        "id": "VLeK3CZIXjgp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBQyTTWTELSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f4b277-dec6-401f-865b-7842be3cfd4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "公開URL: https://2c8c-34-87-46-174.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.87.46.174:8501\u001b[0m\n",
            "\u001b[0m\n",
            "NLTK loaded successfully.\n",
            "2025-04-19 13:29:59.179240: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-19 13:29:59.196762: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745069399.222423    4505 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745069399.229935    4505 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-19 13:29:59.256325: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "config.json: 100% 805/805 [00:00<00:00, 4.63MB/s]\n",
            "model.safetensors.index.json: 100% 24.2k/24.2k [00:00<00:00, 91.5MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/241M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 10.5M/241M [00:00<00:02, 95.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.99G [00:00<00:18, 263MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.99G [00:00<00:14, 340MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 31.5M/241M [00:00<00:01, 128MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.99G [00:00<00:13, 357MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 73.4M/241M [00:00<00:00, 234MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.99G [00:00<00:13, 369MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 115M/241M [00:00<00:00, 299MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.99G [00:00<00:12, 378MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 157M/241M [00:00<00:00, 309MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.99G [00:00<00:12, 385MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 199M/241M [00:00<00:00, 335MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.99G [00:00<00:12, 388MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 241M/241M [00:00<00:00, 293MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.99G [00:00<00:11, 410MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 388M/4.99G [00:00<00:10, 428MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.99G [00:01<00:10, 434MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.99G [00:01<00:10, 439MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 545M/4.99G [00:01<00:10, 419MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.99G [00:01<00:10, 420MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.99G [00:01<00:10, 426MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.99G [00:01<00:09, 437MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.99G [00:01<00:10, 421MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.99G [00:01<00:09, 420MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.99G [00:02<00:09, 414MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.99G [00:02<00:10, 396MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.99G [00:02<00:09, 409MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.99G [00:02<00:09, 418MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.99G [00:02<00:09, 422MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.99G [00:02<00:09, 428MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.99G [00:02<00:08, 430MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.99G [00:02<00:08, 435MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 1.27G/4.99G [00:03<00:08, 427MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.32G/4.99G [00:03<00:08, 434MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.99G [00:03<00:08, 443MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.99G [00:03<00:07, 453MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.99G [00:03<00:07, 463MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.99G [00:03<00:07, 469MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.99G [00:03<00:07, 475MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.99G [00:03<00:07, 478MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.99G [00:04<00:08, 386MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.99G [00:04<00:10, 321MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.99G [00:04<00:11, 286MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.81G/4.99G [00:04<00:11, 275MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/4.99G [00:04<00:11, 277MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.99G [00:04<00:11, 276MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.99G [00:04<00:09, 319MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.99G [00:05<00:08, 354MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.99G [00:05<00:07, 377MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.99G [00:05<00:08, 351MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 2.12G/4.99G [00:05<00:08, 344MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/4.99G [00:05<00:08, 326MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.99G [00:05<00:08, 339MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.99G [00:05<00:08, 332MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.99G [00:05<00:08, 331MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/4.99G [00:06<00:07, 336MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.37G/4.99G [00:06<00:07, 352MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.41G/4.99G [00:06<00:07, 360MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.99G [00:06<00:06, 366MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/4.99G [00:06<00:06, 364MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.99G [00:06<00:06, 363MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.99G [00:06<00:06, 357MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.99G [00:06<00:06, 358MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.66G/4.99G [00:06<00:06, 363MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/4.99G [00:07<00:06, 373MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/4.99G [00:07<00:05, 375MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.99G [00:07<00:05, 392MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/4.99G [00:07<00:05, 395MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.99G [00:07<00:05, 376MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.99G [00:07<00:05, 383MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.99G [00:07<00:05, 397MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.99G [00:08<00:07, 262MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 3.06G/4.99G [00:08<00:06, 292MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.10G/4.99G [00:08<00:05, 320MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.99G [00:08<00:05, 343MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.99G [00:08<00:05, 360MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.99G [00:08<00:04, 370MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.99G [00:08<00:04, 377MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 3.31G/4.99G [00:08<00:04, 382MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.36G/4.99G [00:08<00:04, 370MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/4.99G [00:09<00:04, 365MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.99G [00:09<00:04, 378MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.99G [00:09<00:03, 394MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/4.99G [00:09<00:03, 411MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.99G [00:09<00:03, 438MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 3.65G/4.99G [00:09<00:03, 442MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  74% 3.70G/4.99G [00:09<00:03, 357MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.99G [00:09<00:03, 366MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.99G [00:10<00:03, 376MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.99G [00:10<00:03, 293MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.99G [00:10<00:03, 317MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.99G [00:10<00:03, 352MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.99G [00:10<00:02, 379MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.99G [00:10<00:02, 378MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.99G [00:10<00:02, 380MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.99G [00:10<00:02, 394MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  83% 4.16G/4.99G [00:11<00:02, 388MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 4.20G/4.99G [00:11<00:02, 362MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/4.99G [00:11<00:02, 362MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.99G [00:11<00:01, 373MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.99G [00:11<00:01, 377MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.99G [00:11<00:01, 405MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.99G [00:11<00:01, 431MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.99G [00:11<00:01, 451MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.99G [00:11<00:00, 459MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/4.99G [00:12<00:00, 444MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.65G/4.99G [00:12<00:00, 439MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  94% 4.70G/4.99G [00:12<00:00, 373MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 4.75G/4.99G [00:12<00:00, 399MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/4.99G [00:12<00:00, 373MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/4.99G [00:12<00:00, 382MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/4.99G [00:12<00:00, 401MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.99G [00:12<00:00, 414MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 4.99G/4.99G [00:13<00:00, 381MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:13<00:00,  6.71s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00, 12.49it/s]\n",
            "generation_config.json: 100% 168/168 [00:00<00:00, 1.40MB/s]\n",
            "tokenizer_config.json: 100% 46.9k/46.9k [00:00<00:00, 57.9MB/s]\n",
            "tokenizer.model: 100% 4.24M/4.24M [00:00<00:00, 62.1MB/s]\n",
            "tokenizer.json: 100% 17.5M/17.5M [00:00<00:00, 109MB/s]\n",
            "special_tokens_map.json: 100% 555/555 [00:00<00:00, 4.00MB/s]\n",
            "Device set to use cuda\n",
            "2025-04-19 13:30:28.631 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "Generated response in 18.27s\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/streamlit\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1082, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1697, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1443, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 788, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/cli.py\", line 240, in main_run\n",
            "    _main_run(target, args, flag_options=kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/cli.py\", line 276, in _main_run\n",
            "    bootstrap.run(file, is_hello, args, flag_options)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 355, in run\n",
            "    asyncio.run(main())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
            "    self.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/server/server.py\", line 469, in stop\n",
            "    cli_util.print_to_cli(\"  Stopping...\", fg=\"blue\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/cli_util.py\", line 34, in print_to_cli\n",
            "    click.secho(message, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/termui.py\", line 634, in secho\n",
            "    return echo(message, file=file, nl=nl, err=err, color=color)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/utils.py\", line 318, in echo\n",
            "    file.write(out)  # type: ignore\n",
            "    ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/server/server.py\", line 469, in stop\n",
            "    cli_util.print_to_cli(\"  Stopping...\", fg=\"blue\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/cli_util.py\", line 34, in print_to_cli\n",
            "    click.secho(message, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/termui.py\", line 634, in secho\n",
            "    return echo(message, file=file, nl=nl, err=err, color=color)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/utils.py\", line 318, in echo\n",
            "    file.write(out)  # type: ignore\n",
            "    ^^^^^^^^^^^^^^^\n",
            "RuntimeError: reentrant call inside <_io.BufferedWriter name='<stdout>'>\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phi 4"
      ],
      "metadata": {
        "id": "Y1g4Uv1nXqaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit cache clear"
      ],
      "metadata": {
        "id": "JVEct-CIN8B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app_phi.py"
      ],
      "metadata": {
        "id": "4naIOeLDXwTp",
        "outputId": "a8fed366-7de8-4d8a-b9c1-f1d6ad23f0c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "公開URL: https://81b8-34-87-46-174.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.87.46.174:8501\u001b[0m\n",
            "\u001b[0m\n",
            "NLTK loaded successfully.\n",
            "2025-04-19 13:35:18.469716: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-19 13:35:18.486743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745069718.512901    6122 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745069718.520654    6122 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-19 13:35:18.546698: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "config.json: 100% 2.50k/2.50k [00:00<00:00, 13.0MB/s]\n",
            "model.safetensors.index.json: 100% 16.3k/16.3k [00:00<00:00, 47.4MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.77G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.90G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/2.77G [00:00<00:14, 184MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.90G [00:00<00:51, 94.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 73.4M/2.77G [00:00<00:07, 337MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.90G [00:00<00:34, 139MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 126M/2.77G [00:00<00:06, 396MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/4.90G [00:00<00:24, 194MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 168M/2.77G [00:00<00:06, 385MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.90G [00:00<00:19, 251MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 220M/2.77G [00:00<00:06, 411MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.90G [00:00<00:17, 269MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 273M/2.77G [00:00<00:05, 444MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.90G [00:00<00:17, 272MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 325M/2.77G [00:00<00:05, 460MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.90G [00:00<00:16, 292MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 377M/2.77G [00:00<00:05, 461MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.90G [00:00<00:16, 290MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 430M/2.77G [00:01<00:05, 449MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.90G [00:01<00:14, 311MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 482M/2.77G [00:01<00:05, 433MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.90G [00:01<00:14, 311MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.90G [00:01<00:14, 311MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 535M/2.77G [00:01<00:05, 412MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.90G [00:01<00:15, 296MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 577M/2.77G [00:01<00:05, 408MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 619M/2.77G [00:01<00:05, 405MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.90G [00:01<00:15, 286MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 661M/2.77G [00:01<00:05, 407MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.90G [00:01<00:15, 291MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 703M/2.77G [00:01<00:05, 405MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.90G [00:01<00:13, 319MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 744M/2.77G [00:01<00:05, 402MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.90G [00:01<00:12, 346MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 786M/2.77G [00:01<00:04, 403MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 566M/4.90G [00:01<00:11, 365MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 828M/2.77G [00:02<00:04, 405MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.90G [00:02<00:11, 374MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 870M/2.77G [00:02<00:05, 339MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.90G [00:02<00:14, 297MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 912M/2.77G [00:02<00:07, 257MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.90G [00:02<00:16, 254MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 944M/2.77G [00:02<00:07, 230MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.90G [00:02<00:23, 178MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 975M/2.77G [00:02<00:10, 170MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.90G [00:02<00:23, 176MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.01G/2.77G [00:03<00:09, 189MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 786M/4.90G [00:03<00:21, 195MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 818M/4.90G [00:03<00:20, 200MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.90G [00:03<00:19, 213MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.04G/2.77G [00:03<00:12, 141MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.90G [00:03<00:17, 228MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.07G/2.77G [00:03<00:11, 146MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 912M/4.90G [00:03<00:25, 159MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.09G/2.77G [00:04<00:15, 106MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.90G [00:04<00:32, 120MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.11G/2.77G [00:04<00:17, 94.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.90G [00:04<00:38, 102MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.13G/2.77G [00:04<00:19, 84.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 975M/4.90G [00:04<00:44, 87.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.14G/2.77G [00:04<00:20, 79.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.15G/2.77G [00:05<00:21, 74.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.90G [00:05<00:50, 76.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.16G/2.77G [00:05<00:23, 69.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 1.01G/4.90G [00:05<00:56, 69.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.17G/2.77G [00:05<00:24, 65.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 1.02G/4.90G [00:05<00:55, 70.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.18G/2.77G [00:05<00:23, 68.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.90G [00:05<00:36, 106MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.22G/2.77G [00:05<00:13, 112MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.90G [00:05<00:23, 160MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.26G/2.77G [00:05<00:08, 175MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.90G [00:05<00:17, 211MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.30G/2.77G [00:05<00:06, 230MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.90G [00:05<00:13, 266MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.35G/2.77G [00:05<00:04, 284MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.90G [00:06<00:11, 308MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.41G/2.77G [00:06<00:04, 325MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.90G [00:06<00:10, 338MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.46G/2.77G [00:06<00:03, 355MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.50G/2.77G [00:06<00:03, 368MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.90G [00:06<00:10, 345MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.54G/2.77G [00:06<00:03, 359MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.90G [00:06<00:10, 326MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.58G/2.77G [00:06<00:03, 342MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 1.63G/2.77G [00:06<00:03, 295MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.90G [00:06<00:15, 224MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 1.66G/2.77G [00:07<00:04, 225MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.45G/4.90G [00:07<00:17, 196MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 1.69G/2.77G [00:07<00:05, 193MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.90G [00:07<00:19, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 1.51G/4.90G [00:07<00:17, 189MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 1.73G/2.77G [00:07<00:04, 214MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.55G/4.90G [00:07<00:18, 181MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 1.77G/2.77G [00:07<00:05, 197MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 1.59G/4.90G [00:07<00:15, 219MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 1.81G/2.77G [00:07<00:04, 232MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.90G [00:09<01:07, 48.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 1.85G/2.77G [00:09<00:18, 49.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.90G [00:09<00:47, 68.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 1.89G/2.77G [00:09<00:12, 69.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.70G/4.90G [00:10<00:37, 85.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.94G/2.77G [00:10<00:08, 100MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.90G [00:10<00:30, 105MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 1.98G/2.77G [00:10<00:06, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.02G/2.77G [00:10<00:04, 162MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.90G [00:10<00:23, 136MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.08G/2.77G [00:10<00:03, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.13G/2.77G [00:10<00:02, 251MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.80G/4.90G [00:10<00:23, 134MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.17G/2.77G [00:10<00:02, 277MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.85G/4.90G [00:10<00:17, 173MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.22G/2.77G [00:10<00:01, 316MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.90G/4.90G [00:10<00:13, 221MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.26G/2.77G [00:10<00:01, 338MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.94G/4.90G [00:10<00:12, 246MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.31G/2.77G [00:10<00:01, 343MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.90G [00:11<00:11, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.01G/4.90G [00:11<00:11, 249MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.35G/2.77G [00:11<00:01, 239MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 2.06G/4.90G [00:11<00:10, 276MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 2.40G/2.77G [00:11<00:01, 282MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.09G/4.90G [00:11<00:10, 275MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 2.45G/2.77G [00:11<00:00, 319MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.90G [00:11<00:09, 295MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 2.50G/2.77G [00:11<00:00, 340MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.90G [00:11<00:08, 320MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 2.55G/2.77G [00:11<00:00, 367MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.21G/4.90G [00:11<00:08, 334MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 2.59G/2.77G [00:11<00:00, 279MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.25G/4.90G [00:12<00:11, 221MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 2.64G/2.77G [00:12<00:00, 322MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 2.68G/2.77G [00:12<00:00, 310MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 2.29G/4.90G [00:12<00:12, 203MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 2.73G/2.77G [00:12<00:00, 273MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.90G [00:12<00:16, 159MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 2.77G/2.77G [00:12<00:00, 218MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.36G/4.90G [00:12<00:12, 200MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 2.40G/4.90G [00:12<00:10, 238MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  50% 2.45G/4.90G [00:12<00:08, 285MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.51G/4.90G [00:13<00:07, 326MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 2.56G/4.90G [00:13<00:06, 356MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.90G [00:13<00:06, 380MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.90G [00:13<00:05, 379MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 2.71G/4.90G [00:13<00:06, 349MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.75G/4.90G [00:13<00:05, 362MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.79G/4.90G [00:13<00:05, 375MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 2.84G/4.90G [00:13<00:05, 393MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.89G/4.90G [00:14<00:04, 405MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 2.95G/4.90G [00:14<00:04, 412MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 3.00G/4.90G [00:14<00:04, 416MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.05G/4.90G [00:14<00:04, 420MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 3.10G/4.90G [00:14<00:04, 391MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.15G/4.90G [00:14<00:04, 382MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.19G/4.90G [00:14<00:05, 331MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 3.23G/4.90G [00:15<00:08, 198MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.28G/4.90G [00:15<00:06, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 3.33G/4.90G [00:15<00:05, 285MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.39G/4.90G [00:15<00:04, 322MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.44G/4.90G [00:15<00:04, 353MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 3.48G/4.90G [00:15<00:03, 368MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.52G/4.90G [00:15<00:03, 375MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 3.57G/4.90G [00:16<00:03, 357MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  74% 3.61G/4.90G [00:16<00:03, 364MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 3.66G/4.90G [00:16<00:03, 383MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.71G/4.90G [00:16<00:02, 398MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.75G/4.90G [00:16<00:03, 371MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.80G/4.90G [00:16<00:03, 336MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 3.84G/4.90G [00:16<00:03, 323MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.88G/4.90G [00:17<00:03, 299MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 3.93G/4.90G [00:17<00:02, 341MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 3.97G/4.90G [00:17<00:02, 341MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.03G/4.90G [00:17<00:02, 364MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  83% 4.07G/4.90G [00:17<00:02, 375MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 4.11G/4.90G [00:17<00:02, 373MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.15G/4.90G [00:17<00:01, 381MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 4.19G/4.90G [00:17<00:01, 356MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 4.24G/4.90G [00:17<00:01, 362MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  87% 4.28G/4.90G [00:18<00:01, 373MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.32G/4.90G [00:18<00:01, 382MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 4.36G/4.90G [00:18<00:01, 367MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 4.41G/4.90G [00:18<00:01, 395MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.47G/4.90G [00:18<00:01, 407MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 4.51G/4.90G [00:18<00:00, 399MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.56G/4.90G [00:18<00:00, 408MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  94% 4.61G/4.90G [00:18<00:00, 419MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 4.67G/4.90G [00:18<00:00, 423MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  96% 4.72G/4.90G [00:19<00:00, 380MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 4.76G/4.90G [00:19<00:00, 371MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 4.80G/4.90G [00:19<00:00, 379MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 4.84G/4.90G [00:19<00:00, 389MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 4.90G/4.90G [00:19<00:00, 250MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:19<00:00,  9.98s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00, 39.22it/s]\n",
            "generation_config.json: 100% 168/168 [00:00<00:00, 1.21MB/s]\n",
            "tokenizer_config.json: 100% 2.93k/2.93k [00:00<00:00, 23.6MB/s]\n",
            "vocab.json: 100% 3.91M/3.91M [00:00<00:00, 14.1MB/s]\n",
            "merges.txt: 100% 2.42M/2.42M [00:00<00:00, 5.44MB/s]\n",
            "tokenizer.json: 100% 15.5M/15.5M [00:00<00:00, 105MB/s] \n",
            "added_tokens.json: 100% 249/249 [00:00<00:00, 1.78MB/s]\n",
            "special_tokens_map.json: 100% 587/587 [00:00<00:00, 4.47MB/s]\n",
            "Device set to use cuda\n",
            "2025-04-19 13:35:54.063 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "Generated response in 11.48s\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bbixo8S_42Q"
      },
      "source": [
        "アプリケーションの機能としては、チャット機能や履歴閲覧があります。\n",
        "\n",
        "これらの機能を実現するためには、StreamlitによるUI部分だけではなく、SQLiteを使用したチャット履歴の保存やLLMのモデルを呼び出した推論などの処理を組み合わせることで実現しています。\n",
        "\n",
        "- **`app.py`**: アプリケーションのエントリーポイント。チャット機能、履歴閲覧、サンプルデータ管理のUIを提供します。\n",
        "- **`ui.py`**: チャットページや履歴閲覧ページなど、アプリケーションのUIロジックを管理します。\n",
        "- **`llm.py`**: LLMモデルのロードとテキスト生成を行うモジュール。\n",
        "- **`database.py`**: SQLiteデータベースを使用してチャット履歴やフィードバックを保存・管理します。\n",
        "- **`metrics.py`**: BLEUスコアやコサイン類似度など、回答の評価指標を計算するモジュール。\n",
        "- **`data.py`**: サンプルデータの作成やデータベースの初期化を行うモジュール。\n",
        "- **`config.py`**: アプリケーションの設定（モデル名やデータベースファイル名）を管理します。\n",
        "- **`requirements.txt`**: このアプリケーションを実行するために必要なPythonパッケージ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvm8sWFPELSP"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFJC2TmZELSP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "G2waG0JmUXZX",
        "outputId": "bdcdccc7-819c-48cf-824e-ed193b1ce91f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app_phi.py  chat_feedback.db  database.py  llm.py      __pycache__\t ui.py\n",
            "app.py\t    config.py\t      data.py\t   metrics.py  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "conn = sqlite3.connect(\"chat_feedback.db\")\n",
        "c = conn.cursor()\n",
        "\n",
        "c.execute(\"SELECT * FROM chat_history\")\n",
        "rows = c.fetchall()\n",
        "for row in rows:\n",
        "    print(row)\n",
        "\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "1BOD7qXkUku-",
        "outputId": "0c770c93-6ed1-4704-d728-0fc4afdd42cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, '2025-04-19 04:25:20', 'Pythonのリスト内包表記とは何ですか？', 'リスト内包表記は、既存のリストから新しいリストを作成するためのPythonの構文です。通常のfor文よりも簡潔に記述でき、パフォーマンスも向上する場合があります。', '部分的に正確: 基本的な説明は正しいですが、具体的な構文例が示されていません', 'Pythonのリスト内包表記は、リストを簡潔に作成するための構文で、`[expression for item in iterable if condition]`の形式で書きます。通常のforループよりも短く書けて、実行速度も速い場合があります。', 0.5, 1.2, 0.0, 0.0, 41, 0.0)\n",
            "(2, '2025-04-19 04:25:20', '機械学習における過学習とは？', '過学習（オーバーフィッティング）とは、機械学習モデルが訓練データに対して過度に適合し、新しいデータに対する汎化性能が低下する現象です。', '正確: 過学習の本質をよく捉えています', '過学習（オーバーフィッティング）は、モデルがトレーニングデータに過度に適合し、未知のデータに対する予測性能が低下する現象です。モデルが訓練データのノイズまで学習してしまうことが原因です。', 1.0, 1.5, 0.0, 0.25233420143369617, 32, 0.3333333333333333)\n",
            "(3, '2025-04-19 04:25:21', '量子コンピュータの基本原理は？', '量子コンピュータは量子力学の原理に基づいて動作します。従来のビットの代わりに量子ビット（キュービット）を使用し、重ね合わせと量子もつれの特性により並列計算を実現します。', '部分的に正確: 基本概念は正しいですが、詳細な説明が不足しています', '量子コンピュータは量子力学的現象を利用した計算機で、従来のビットではなく量子ビット（キュービット）を使用します。キュービットは重ね合わせ状態をとることができ、複数の状態を同時に表現できます。また量子もつれにより、従来のコンピュータでは困難な特定の問題を効率的に解くことができます。', 0.5, 2.1, 0.0, 0.08704446792504217, 44, 0.125)\n",
            "(4, '2025-04-19 04:25:21', 'Streamlitとは何ですか？', 'Streamlitは、Pythonで書かれたデータサイエンスやAIアプリケーションを簡単に作成するためのオープンソースフレームワークです。数行のコードでインタラクティブなWebアプリを作成できます。', '正確: Streamlitの基本概念と利点をよく説明しています', 'Streamlitは、データサイエンティストやAIエンジニアがPythonを使って簡単にWebアプリケーションを構築できるフレームワークです。少ないコード量で、インタラクティブなダッシュボードやデータ可視化アプリケーションを作成できます。', 1.0, 0.9, 0.0, 0.17077611319011649, 36, 0.25)\n",
            "(5, '2025-04-19 04:25:21', 'ブロックチェーンの仕組みを説明してください', 'ブロックチェーンは、分散型台帳技術の一つで、データをブロックに格納し、暗号技術でリンクして改ざん防止を実現します。各ブロックには前のブロックのハッシュ値が含まれ、チェーン状に連結されています。', '部分的に正確: 基本的な説明はありますが、コンセンサスメカニズムについての言及がありません', 'ブロックチェーンは分散型台帳技術で、データブロックが暗号学的にリンクされた構造です。各ブロックには取引データとタイムスタンプ、前ブロックのハッシュ値が含まれます。分散型ネットワークでコンセンサスアルゴリズムにより検証され、改ざんが極めて困難なシステムを実現しています。', 0.5, 1.8, 0.0, 0.0, 56, 0.0)\n",
            "(6, '2025-04-19 04:25:21', 'ディープラーニングとは何ですか？', 'ディープラーニングは、複数の層からなるニューラルネットワークを用いた機械学習手法です。画像認識や自然言語処理など複雑なタスクに優れています。', '部分的に正確: 基本的な定義は正しいですが、詳細な説明が不足しています', 'ディープラーニングは多層ニューラルネットワークを使用した機械学習の一種で、特徴抽出を自動的に行う能力があります。画像認識、自然言語処理、音声認識などの複雑なタスクで革命的な成果を上げており、大量のデータと計算リソースを活用して従来の手法を超える性能を実現しています。', 0.5, 1.3, 0.0, 0.0, 33, 0.0)\n",
            "(7, '2025-04-19 04:25:21', 'SQLインジェクションとは何ですか？', 'SQLインジェクションは、Webアプリケーションの脆弱性を悪用して不正なSQLクエリを実行させる攻撃手法です。ユーザー入力を適切に検証・サニタイズしないことで発生します。', '正確: SQLインジェクションの本質と発生メカニズムをよく説明しています', 'SQLインジェクションは、Webアプリケーションのセキュリティ脆弱性を悪用した攻撃手法で、攻撃者がユーザー入力フィールドを通じて悪意のあるSQLコードを挿入し、データベースに不正なクエリを実行させます。これにより、データの漏洩、改ざん、削除などの被害が生じる可能性があります。防止策としては、パラメータ化クエリの使用、入力のバリデーション、最小権限の原則などがあります。', 1.0, 1.6, 0.0, 0.07970251181266945, 41, 0.08333333333333333)\n",
            "(8, '2025-04-19 04:25:21', 'NFTとは何ですか？', 'NFT（Non-Fungible Token）は、代替不可能なトークンで、デジタルアセットの所有権を証明するためのブロックチェーン技術です。デジタルアート、コレクティブル、音楽などに利用されています。', '正確: NFTの基本概念とユースケースを明確に説明しています', 'NFT（Non-Fungible Token、非代替性トークン）はブロックチェーン上に記録された固有の識別子を持つデジタル資産です。通常の暗号通貨と異なり、各NFTは独自の価値を持ち、交換不可能です。デジタルアート、音楽、ゲーム内アイテム、バーチャル不動産など様々なデジタル資産の所有権証明や取引に利用されています。', 1.0, 1.4, 0.0, 0.30520621747310006, 46, 0.38461538461538464)\n",
            "(9, '2025-04-19 04:25:21', 'Pythonのデコレータとは何ですか？', 'デコレータは、関数やメソッドを修飾するための構文で、@記号を使用します。関数の機能を変更したり拡張したりするための便利な方法です。', '部分的に正確: 基本的な説明はありますが、デコレータが高階関数であることや具体的な使用例の説明が不足しています', 'Pythonのデコレータは、既存の関数やメソッドを修飾して機能を拡張するための構文です。@記号を使用して関数定義の前に配置します。デコレータは高階関数で、別の関数を引数として受け取り、新しい関数を返します。ロギング、認証、キャッシングなど、コードの重複を避けながら横断的関心事を実装するのに役立ちます。', 0.5, 1.2, 0.0, 0.0, 39, 0.0)\n",
            "(10, '2025-04-19 04:25:21', 'コンテナ技術とは何ですか？', 'コンテナ技術は、アプリケーションとその依存関係をパッケージ化し、異なる環境で一貫して実行できるようにする軽量な仮想化技術です。', '部分的に正確: 基本的な説明はありますが、仮想マシンとの違いやDockerなどの具体例の説明が不足しています', 'コンテナ技術は、アプリケーションとその依存関係（ライブラリ、バイナリなど）を一つのパッケージにカプセル化する軽量な仮想化技術です。コンテナは仮想マシンよりも軽量で起動が速く、ホストOSのカーネルを共有します。Dockerが代表的なコンテナプラットフォームで、アプリケーションの開発、テスト、デプロイメントを効率化し、「どこでも同じように動作する」環境を提供します。', 0.5, 1.1, 0.0, 0.09042421401858962, 32, 0.07692307692307693)\n",
            "(11, '2025-04-19 04:30:53', 'LLMとはなにですか？\\n', 'LLMとは、Large Language Modelsの略であり、これは大量の自然言語データを使用して、文章、質問、命令などのさまざまなテキスト入力を生成することができる人工知能モデルのことです。これらのモデルは、OpenAIによって開発されたGPT（Generative Pre-trained Transformer）シリーズの一部であり、Google、Microsoftなどの企業によっても開発されています。LLMは、会話システム、翻訳ツール、コンテンツ生成ツールなど、さまざまなアプリケーションで使用されています。', '正確', '', 1.0, 7.402844667434692, 0.0, 0.0, 117, 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUXhIzV7ELSP"
      },
      "source": [
        "# 03_FastAPI\n",
        "\n",
        "ディレクトリ「03_FastAPI」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4ejjDLxr3kfC",
        "outputId": "accf4650-476c-41d1-d812-438572d2db9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/03_FastAPI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/03_FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45TDsNzELSQ"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9uv6glCz5a7Z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfrmE2VmELSQ"
      },
      "source": [
        "ngrokとhuggigfaceのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ELzWhMFORRIO",
        "outputId": "9cd08c41-f86f-48bf-e00a-6877306bb1f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "The token `agent` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `agent`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-wztc2CELSQ"
      },
      "source": [
        "アプリを起動します。\n",
        "\n",
        "「02_streamlit_app」から続けて「03_FastAPI」を実行している場合は、モデルのダウンロードが済んでいるため、すぐにサービスが立ち上がります。\n",
        "\n",
        "「03_FastAPI」のみを実行している場合は、初回の起動時にモデルのダウンロードが始まるので、モデルのダウンロードが終わるまで数分間待ちましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gemma 2"
      ],
      "metadata": {
        "id": "cOVgfdIqeupW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meQ4SwISn3IQ"
      },
      "outputs": [],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phi 4"
      ],
      "metadata": {
        "id": "4tM0HPaaey-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "promptに以下を加えた。\n",
        "- 答えを教えるのではなく、一緒に考えるように促すようにしてください。\n",
        "- 会話は質問で終わるようにしてください。\n",
        "\n",
        "Rather than just providing an answer, try to guide the user to think with you. Always finish your response with a question."
      ],
      "metadata": {
        "id": "rmiZXuASnAa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python app_phi.py"
      ],
      "metadata": {
        "id": "C61aXXXBfEcD",
        "outputId": "7d98ba5b-0899-4551-a3c1-ce47ab489587",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-20 14:40:49.990016: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-20 14:40:50.007871: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745160050.029863    2444 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745160050.036437    2444 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-20 14:40:50.058720: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "モデル名を設定: microsoft/Phi-4-mini-instruct\n",
            "/content/lecture-ai-engineering/day1/03_FastAPI/app_phi.py:135: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n",
            "FastAPIエンドポイントを定義しました。\n",
            "アクティブなngrokトンネルはありません。\n",
            "ポート8501に新しいngrokトンネルを開いています...\n",
            "---------------------------------------------------------------------\n",
            "✅ 公開URL:   https://0e8f-34-143-174-225.ngrok-free.app\n",
            "📖 APIドキュメント (Swagger UI): https://0e8f-34-143-174-225.ngrok-free.app/docs\n",
            "---------------------------------------------------------------------\n",
            "(APIクライアントやブラウザからアクセスするためにこのURLをコピーしてください)\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m2444\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "load_model_task: モデルの読み込みを開始...\n",
            "使用デバイス: cuda\n",
            "config.json: 100% 2.50k/2.50k [00:00<00:00, 17.4MB/s]\n",
            "model.safetensors.index.json: 100% 16.3k/16.3k [00:00<00:00, 58.6MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.90G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.90G [00:00<00:23, 207MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.77G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.90G [00:00<00:13, 350MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/2.77G [00:00<00:16, 166MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.90G [00:00<00:13, 364MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   3% 73.4M/2.77G [00:00<00:08, 317MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.90G [00:00<00:11, 399MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   5% 126M/2.77G [00:00<00:07, 359MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.90G [00:00<00:12, 387MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   6% 178M/2.77G [00:00<00:06, 404MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.90G [00:00<00:12, 370MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   8% 220M/2.77G [00:00<00:06, 405MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.90G [00:00<00:12, 379MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  10% 273M/2.77G [00:00<00:05, 421MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  12% 325M/2.77G [00:00<00:05, 450MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.90G [00:00<00:13, 338MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  14% 377M/2.77G [00:00<00:05, 441MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.90G [00:01<00:12, 352MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 419M/4.90G [00:01<00:15, 290MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  16% 430M/2.77G [00:01<00:07, 321MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.90G [00:01<00:19, 225MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  17% 472M/2.77G [00:01<00:08, 282MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.90G [00:01<00:17, 258MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  19% 514M/2.77G [00:01<00:08, 272MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.90G [00:01<00:15, 281MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  20% 556M/2.77G [00:01<00:07, 292MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.90G [00:01<00:14, 304MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  22% 598M/2.77G [00:01<00:06, 313MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.90G [00:01<00:12, 339MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  23% 640M/2.77G [00:01<00:06, 336MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.90G [00:02<00:11, 370MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  25% 692M/2.77G [00:02<00:05, 369MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.90G [00:02<00:10, 386MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  27% 734M/2.77G [00:02<00:05, 381MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.90G [00:02<00:10, 394MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  28% 776M/2.77G [00:02<00:05, 370MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 818M/4.90G [00:02<00:10, 377MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 818M/2.77G [00:02<00:05, 381MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 870M/4.90G [00:02<00:10, 390MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  31% 860M/2.77G [00:02<00:05, 369MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  33% 902M/2.77G [00:02<00:05, 360MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 912M/4.90G [00:02<00:11, 360MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  34% 944M/2.77G [00:04<00:31, 57.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.90G [00:04<01:06, 59.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  36% 996M/2.77G [00:04<00:21, 81.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.01G/4.90G [00:05<00:46, 83.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.06G/4.90G [00:05<00:33, 114MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 1.03G/2.77G [00:05<00:18, 95.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.11G/4.90G [00:05<00:25, 148MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 1.07G/2.77G [00:05<00:13, 124MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.15G/4.90G [00:05<00:21, 177MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  41% 1.12G/2.77G [00:05<00:09, 166MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  42% 1.16G/2.77G [00:05<00:08, 200MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.21G/4.90G [00:05<00:17, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.90G [00:05<00:14, 248MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  44% 1.21G/2.77G [00:05<00:06, 229MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.90G [00:05<00:13, 273MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  45% 1.25G/2.77G [00:05<00:06, 252MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.90G [00:05<00:12, 295MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  47% 1.29G/2.77G [00:05<00:05, 276MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.90G [00:05<00:11, 318MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 1.33G/2.77G [00:05<00:04, 299MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.90G [00:06<00:09, 352MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  50% 1.37G/2.77G [00:05<00:04, 299MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.47G/4.90G [00:06<00:10, 328MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  51% 1.42G/2.77G [00:06<00:04, 313MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.51G/4.90G [00:06<00:10, 327MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  53% 1.46G/2.77G [00:06<00:04, 318MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.55G/4.90G [00:06<00:10, 326MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 1.50G/2.77G [00:06<00:03, 328MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  56% 1.54G/2.77G [00:06<00:03, 343MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.59G/4.90G [00:06<00:10, 325MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 1.58G/2.77G [00:06<00:03, 341MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.90G [00:06<00:09, 335MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.90G [00:06<00:09, 347MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  59% 1.63G/2.77G [00:06<00:03, 331MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.72G/4.90G [00:07<00:11, 273MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 1.67G/2.77G [00:06<00:04, 256MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.75G/4.90G [00:07<00:13, 232MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  61% 1.70G/2.77G [00:07<00:05, 211MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/4.90G [00:07<00:15, 206MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  62% 1.73G/2.77G [00:07<00:04, 209MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.90G [00:07<00:14, 219MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  64% 1.76G/2.77G [00:07<00:04, 225MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.87G/4.90G [00:07<00:13, 230MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 1.80G/2.77G [00:07<00:04, 212MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.90G/4.90G [00:07<00:12, 238MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  66% 1.84G/2.77G [00:07<00:04, 212MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.90G [00:08<00:13, 215MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  67% 1.87G/2.77G [00:07<00:04, 206MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.97G/4.90G [00:08<00:11, 245MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  69% 1.91G/2.77G [00:08<00:04, 199MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.00G/4.90G [00:08<00:13, 216MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  70% 1.95G/2.77G [00:08<00:03, 230MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.90G [00:08<00:13, 213MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  72% 1.98G/2.77G [00:08<00:03, 213MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.90G [00:08<00:12, 224MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  73% 2.01G/2.77G [00:08<00:03, 218MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.10G/4.90G [00:08<00:12, 228MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 2.04G/2.77G [00:08<00:03, 211MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 2.08G/2.77G [00:10<00:15, 43.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  77% 2.14G/2.77G [00:11<00:08, 74.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.90G [00:11<01:11, 38.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  79% 2.18G/2.77G [00:11<00:06, 97.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.90G [00:11<00:43, 62.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  81% 2.23G/2.77G [00:11<00:04, 133MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.23G/4.90G [00:11<00:29, 91.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  82% 2.28G/2.77G [00:11<00:03, 161MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.29G/4.90G [00:11<00:20, 128MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.35G/4.90G [00:11<00:14, 177MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  84% 2.32G/2.77G [00:11<00:02, 181MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.40G/4.90G [00:11<00:11, 219MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 2.36G/2.77G [00:11<00:01, 214MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.45G/4.90G [00:11<00:09, 259MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 2.40G/2.77G [00:11<00:01, 236MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.51G/4.90G [00:12<00:08, 290MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  88% 2.44G/2.77G [00:11<00:01, 270MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.56G/4.90G [00:12<00:07, 317MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  90% 2.49G/2.77G [00:12<00:00, 290MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  91% 2.53G/2.77G [00:12<00:00, 318MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.60G/4.90G [00:12<00:06, 332MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.64G/4.90G [00:12<00:06, 340MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  93% 2.57G/2.77G [00:12<00:00, 310MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  94% 2.61G/2.77G [00:12<00:00, 325MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.68G/4.90G [00:12<00:07, 317MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 2.65G/2.77G [00:12<00:00, 329MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.73G/4.90G [00:12<00:07, 305MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  97% 2.69G/2.77G [00:12<00:00, 312MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.77G/4.90G [00:12<00:06, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.82G/4.90G [00:12<00:05, 350MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  99% 2.74G/2.77G [00:12<00:00, 255MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.86G/4.90G [00:13<00:06, 306MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 2.77G/2.77G [00:13<00:00, 229MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 2.77G/2.77G [00:13<00:00, 211MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 2.97G/4.90G [00:13<00:05, 376MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.02G/4.90G [00:13<00:04, 393MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.06G/4.90G [00:13<00:04, 377MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.10G/4.90G [00:13<00:04, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.15G/4.90G [00:13<00:04, 386MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.19G/4.90G [00:14<00:05, 307MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.24G/4.90G [00:14<00:04, 355MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.29G/4.90G [00:14<00:04, 392MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.36G/4.90G [00:14<00:03, 440MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.90G [00:14<00:03, 436MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.46G/4.90G [00:14<00:03, 435MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.51G/4.90G [00:14<00:03, 391MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.58G/4.90G [00:14<00:03, 411MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.63G/4.90G [00:15<00:03, 395MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.67G/4.90G [00:17<00:18, 66.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.72G/4.90G [00:17<00:13, 90.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.76G/4.90G [00:17<00:10, 113MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.81G/4.90G [00:17<00:07, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.85G/4.90G [00:17<00:06, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.89G/4.90G [00:17<00:05, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.93G/4.90G [00:17<00:04, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 3.97G/4.90G [00:18<00:03, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.03G/4.90G [00:18<00:03, 292MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.08G/4.90G [00:18<00:02, 327MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.12G/4.90G [00:18<00:02, 348MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.16G/4.90G [00:18<00:02, 345MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.22G/4.90G [00:18<00:01, 372MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.27G/4.90G [00:18<00:01, 394MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.32G/4.90G [00:18<00:01, 411MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.37G/4.90G [00:19<00:01, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.42G/4.90G [00:19<00:01, 307MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.48G/4.90G [00:19<00:01, 338MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.53G/4.90G [00:19<00:01, 365MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.57G/4.90G [00:19<00:00, 361MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.62G/4.90G [00:19<00:00, 387MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.67G/4.90G [00:19<00:00, 378MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.71G/4.90G [00:20<00:00, 355MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.76G/4.90G [00:20<00:00, 396MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.81G/4.90G [00:20<00:00, 428MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.90G/4.90G [00:20<00:00, 239MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:20<00:00, 10.41s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00, 41.28it/s]\n",
            "generation_config.json: 100% 168/168 [00:00<00:00, 1.36MB/s]\n",
            "tokenizer_config.json: 100% 2.93k/2.93k [00:00<00:00, 20.0MB/s]\n",
            "vocab.json: 100% 3.91M/3.91M [00:00<00:00, 8.20MB/s]\n",
            "merges.txt: 100% 2.42M/2.42M [00:00<00:00, 2.68MB/s]\n",
            "tokenizer.json: 100% 15.5M/15.5M [00:00<00:00, 276MB/s]\n",
            "added_tokens.json: 100% 249/249 [00:00<00:00, 2.17MB/s]\n",
            "special_tokens_map.json: 100% 587/587 [00:00<00:00, 5.00MB/s]\n",
            "Device set to use cuda\n",
            "モデル 'microsoft/Phi-4-mini-instruct' の読み込みに成功しました\n",
            "load_model_task: モデルの読み込みが完了しました。\n",
            "起動時にモデルの初期化が完了しました。\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8501\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     2400:2410:b240:3300:4498:da7b:2f2:3155:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2400:2410:b240:3300:4498:da7b:2f2:3155:0 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2400:2410:b240:3300:4498:da7b:2f2:3155:0 - \"\u001b[1mGET /docs HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     2400:2410:b240:3300:4498:da7b:2f2:3155:0 - \"\u001b[1mGET /openapi.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "シンプルなリクエストを受信: prompt=LLMとはなにですか？..., max_new_tokens=512\n",
            "モデル推論を開始...\n",
            "モデル推論が完了しました。\n",
            "抽出されたアシスタント応答: 答え: LLMはLarge Language Modelを指します。これは、自然言語処理や生成において使用される深層学習モデルの一種です。これらのモデルは、大量のテキストデータを学習することで、文法、...\n",
            "応答生成時間: 9.03秒\n",
            "\u001b[32mINFO\u001b[0m:     2400:2410:b240:3300:4498:da7b:2f2:3155:0 - \"\u001b[1mPOST /generate HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLubjIhbELSR"
      },
      "source": [
        "FastAPIが起動すると、APIとクライアントが通信するためのURL（エンドポイント）が作られます。\n",
        "\n",
        "URLが作られるのと合わせて、Swagger UIというWebインターフェースが作られます。\n",
        "\n",
        "Swagger UIにアクセスすることで、APIの仕様を確認できたり、APIをテストすることができます。\n",
        "\n",
        "Swagger UIを利用することで、APIを通してLLMを動かしてみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgumW3mGELSR"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RJymTZio-WPJ"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}